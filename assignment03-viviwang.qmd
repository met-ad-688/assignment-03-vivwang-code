---
title: Assignment 03
author:
  - name: Wei Wang
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2025-09-20'
format:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2
  docx: default
  pdf: default
date-modified: today
date-format: long
execute:
  echo: true
  eval: false
  freeze: auto
---

# Load the Dataset

```{python}
from pyspark.sql import SparkSession
import pandas as pd
import plotly.express as px
import plotly.io as pio
pio.renderers.default = "svg"
from pyspark.sql import SparkSession
import re
import numpy as np
import plotly.graph_objects as go
from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when
from pyspark.sql import functions as F
from pyspark.sql.functions import monotonically_increasing_id

np.random.seed(28)

pio.renderers.default = "notebook"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("data/lightcast_job_postings.csv")

# Show Schema and Sample Data
# print("---This is Diagnostic check, No need to print it in the final doc---")

# df.printSchema() # comment this line when rendering the submission
# df.show(5)

```

# Data Preparation
```{python}
# Step 1 Casting salary and experience columns
df = df.withColumn("SALARY", col("SALARY").cast("float"))\
       .withColumn("SALARY_FROM", col("SALARY_FROM").cast("float"))\
       .withColumn("SALARY_TO", col("SALARY_TO").cast("float"))\
       .withColumn("MIN_YEARS_EXPERIENCE", col("MIN_YEARS_EXPERIENCE").cast("float"))\
       .withColumn("MAX_YEARS_EXPERIENCE", col("MAX_YEARS_EXPERIENCE").cast("float"))

# Step 2 Computing median for salary columns
def compute_median(sdf,col_name):
  q = sdf.approxQuantile(col_name,[0.5],0.01)
  return q[0] if q else None

median_from = compute_median(df,"SALARY_FROM")
median_to = compute_median(df,"SALARY_TO")
median_salary = compute_median(df,"SALARY")

print("Medians:",median_from, median_to, median_salary)

# Step 3 Imputing missing salaries, but not experience
df = df.fillna({
  "SALARY_FROM": median_from,
  "SALARY_TO": median_to,
  "SALARY": median_salary
})

# Step 4 Computing average salary
df = df.withColumn("Average_Salary",(col("SALARY_FROM")+col("SALARY_TO"))/2)

# Step 5 Selecting required columns
export_cols = [
  "EDUCATION_LEVELS_NAME",
  "REMOTE_TYPE_NAME",
  "MAX_YEARS_EXPERIENCE",
  "Average_Salary",
  "SALARY",
  "LOT_V6_SPECIALIZED_OCCUPATION_NAME"
]
df_selected = df.select(*export_cols)

# Step 6 Saving to CSV
pdf = df_selected.toPandas()
pdf.to_csv("data/lightcast_cleaned.csv", index=False)

print("Data cleaning complete. Rows retained:", len(pdf))
```


# Salary Distribution by Industry and Employment Type
- Compare salary variations across industries.
- **Filter the dataset**
  - Remove records where **salary is missing or zero**.
- **Aggregate Data**
  - Group by **NAICS industry codes**.
  - Group by **employment type** and compute salary distribution.
- **Visualize results**
  - Create a **box plot** where:
    - **X-axis** = `NAICS2_NAME`
    - **Y-axis** = `SALARY_FROM`
    - Group by E`MPLOYMENT_TYPE_NAME`.
  - Customize colors, fonts, and styles.
- **Explanation**: 

```{python}

```